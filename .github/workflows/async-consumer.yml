# Async Consumer - Triggered when async processing completes
# This workflow consumes results from completed async jobs

name: Async Consumer Pipeline

on:
  repository_dispatch:
    types: [async_job_completed]
  workflow_dispatch:
    inputs:
      action_id:
        description: 'Action ID to consume results for'
        required: true
      correlation_id:
        description: 'Correlation ID (optional)'
        required: false
      force_consume:
        description: 'Force consumption even if job not complete'
        required: false
        default: false
        type: boolean

env:
  CONSUMER_ACTION_ID: consumer-${{ github.run_id }}-${{ github.run_attempt }}

jobs:
  # ================================
  # ASYNC RESULT CONSUMER  
  # ================================
  consume-async-results:
    runs-on: self-hosted
    outputs:
      consumed-action-id: ${{ steps.consume.outputs.consumed-action-id }}
      job-status: ${{ steps.consume.outputs.job-status }}
      performance-metrics: ${{ steps.consume.outputs.performance-metrics }}
      correlation-verified: ${{ steps.consume.outputs.correlation-verified }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        
      - name: Parse Trigger Context
        id: context
        run: |
          echo "ðŸ” Parsing trigger context..."
          
          if [[ "${{ github.event_name }}" == "repository_dispatch" ]]; then
            # Triggered by completion monitor
            ACTION_ID="${{ github.event.client_payload.action_id }}"
            CORRELATION_ID="${{ github.event.client_payload.correlation_id }}"
            JOB_STATUS="${{ github.event.client_payload.status }}"
            TRIGGER_TYPE="automatic"
            
            echo "ðŸ”” Automatically triggered by completion event"
            echo "ðŸ“‹ Dispatch payload:"
            echo '${{ toJson(github.event.client_payload) }}'
          else
            # Manually triggered
            ACTION_ID="${{ github.event.inputs.action_id }}"
            CORRELATION_ID="${{ github.event.inputs.correlation_id }}"
            JOB_STATUS="unknown"
            TRIGGER_TYPE="manual"
            
            echo "ðŸ‘¤ Manually triggered by user"
          fi
          
          echo "action-id=$ACTION_ID" >> $GITHUB_OUTPUT
          echo "correlation-id=$CORRELATION_ID" >> $GITHUB_OUTPUT
          echo "job-status=$JOB_STATUS" >> $GITHUB_OUTPUT
          echo "trigger-type=$TRIGGER_TYPE" >> $GITHUB_OUTPUT
          
          echo "ðŸ†” Target Action ID: $ACTION_ID"
          echo "ðŸ”— Correlation ID: ${CORRELATION_ID:-'Not provided'}"
          echo "ðŸ“Š Job Status: $JOB_STATUS"
          echo "ðŸŽ¯ Trigger Type: $TRIGGER_TYPE"

      - name: Verify Job Completion
        id: verify
        run: |
          ACTION_ID="${{ steps.context.outputs.action-id }}"
          FORCE_CONSUME="${{ github.event.inputs.force_consume }}"
          
          echo "ðŸ” Verifying job completion for: $ACTION_ID"
          
          job_complete=false
          completion_status=""
          
          # Check if results file exists
          results_file="/tmp/math-results-$ACTION_ID.json"
          if [[ -f "$results_file" ]]; then
            echo "ðŸ“‹ Results file found: $results_file"
            
            if command -v jq >/dev/null; then
              completed_at=$(jq -r '.completed_at // empty' "$results_file" 2>/dev/null)
              if [[ -n "$completed_at" ]]; then
                job_complete=true
                completion_status="completed"
                echo "âœ… Job marked as completed at: $completed_at"
              fi
            fi
          fi
          
          # Check indexed outputs
          if ./scripts/pubsub/output-query-api.sh get-status "$ACTION_ID" "math" >/dev/null 2>&1; then
            echo "ðŸ“Š Indexed outputs found for job"
            if [[ "$job_complete" != "true" ]]; then
              completion_status="processing"
            fi
          fi
          
          # Force consume if requested
          if [[ "$FORCE_CONSUME" == "true" ]]; then
            echo "âš ï¸  Force consume enabled - proceeding regardless of completion status"
            job_complete=true
            completion_status="forced"
          fi
          
          echo "job-complete=$job_complete" >> $GITHUB_OUTPUT
          echo "completion-status=$completion_status" >> $GITHUB_OUTPUT
          
          if [[ "$job_complete" != "true" ]]; then
            echo "âŒ Job not yet complete. Current status: ${completion_status:-'unknown'}"
            echo "ðŸ’¡ To consume partial results, re-run with force_consume=true"
            exit 1
          fi
          
          echo "âœ… Job ready for consumption. Status: $completion_status"

      - name: Consume Processing Results
        id: consume
        run: |
          ACTION_ID="${{ steps.context.outputs.action-id }}"
          CORRELATION_ID="${{ steps.context.outputs.correlation-id }}"
          
          echo "ðŸ½ï¸  Consuming results for action: $ACTION_ID"
          
          # Initialize output variables
          consumed_results=""
          performance_data=""
          correlation_verified="false"
          
          # 1. Consume indexed outputs
          echo "ðŸ“Š Retrieving indexed outputs..."
          
          if JOB_STATUS=$(./scripts/pubsub/output-query-api.sh get-status "$ACTION_ID" "math" 2>/dev/null); then
            echo "âœ… Job Status from indexed storage: $JOB_STATUS"
            echo "job-status=$JOB_STATUS" >> $GITHUB_OUTPUT
          else
            echo "âš ï¸  No indexed status found"
            echo "job-status=not-found" >> $GITHUB_OUTPUT
          fi
          
          # 2. Retrieve processing logs
          echo "ðŸ“„ Retrieving processing logs..."
          
          log_file="/tmp/consumer-logs-$ACTION_ID.txt"
          if ./scripts/pubsub/output-query-api.sh get-logs "$ACTION_ID" "math" 100 > "$log_file"; then
            log_count=$(wc -l < "$log_file")
            echo "âœ… Retrieved $log_count log lines"
            
            # Extract key metrics from logs
            if grep -q "operations_per_second" "$log_file"; then
              performance_data=$(grep "operations_per_second" "$log_file" | tail -1 | jq -r '.statistics.operations_per_second // "unknown"' 2>/dev/null || echo "unknown")
              echo "âš¡ Performance: $performance_data ops/sec"
            fi
          else
            echo "âš ï¸  No processing logs found"
            log_count=0
          fi
          
          # 3. Verify correlation tracking
          if [[ -n "$CORRELATION_ID" ]]; then
            echo "ðŸ”— Verifying correlation tracking..."
            
            if ./scripts/pubsub/output-query-api.sh search "$ACTION_ID" "math" "$CORRELATION_ID" >/dev/null; then
              correlation_verified="true"
              echo "âœ… Correlation ID found in outputs"
            else
              echo "âŒ Correlation ID not found in outputs"
            fi
          fi
          
          # 4. Consume results file
          results_file="/tmp/math-results-$ACTION_ID.json"
          if [[ -f "$results_file" ]]; then
            echo "ðŸ“‹ Consuming results file..."
            
            # Extract key information
            if command -v jq >/dev/null; then
              total_processed=$(jq -r '.processed_count // 0' "$results_file")
              operation_type=$(jq -r '.operation // "unknown"' "$results_file")
              total_time=$(jq -r '.statistics.total_time_ms // 0' "$results_file")
              ops_per_sec=$(jq -r '.statistics.operations_per_second // 0' "$results_file")
              
              echo "ðŸ“Š Processing Summary:"
              echo "  Operation: $operation_type"
              echo "  Processed: $total_processed operations"
              echo "  Duration: ${total_time}ms"
              echo "  Performance: $ops_per_sec ops/sec"
              
              performance_data="$ops_per_sec"
            fi
            
            # Create consumption summary
            consumption_summary="/tmp/consumption-summary-$ACTION_ID.json"
            cat > "$consumption_summary" << EOF
{
  "consumed_at": "$(date -Iseconds)",
  "consumer_action_id": "${{ env.CONSUMER_ACTION_ID }}",
  "consumed_action_id": "$ACTION_ID",
  "correlation_id": "$CORRELATION_ID",
  "correlation_verified": $correlation_verified,
  "job_status": "$JOB_STATUS",
  "processing_results": $(cat "$results_file" 2>/dev/null || echo '{}'),
  "log_lines_retrieved": $log_count,
  "performance_metrics": {
    "operations_per_second": $ops_per_sec,
    "total_processing_time_ms": $total_time
  },
  "github_context": {
    "repository": "${{ github.repository }}",
    "consumer_run_id": "${{ github.run_id }}",
    "trigger_type": "${{ steps.context.outputs.trigger-type }}"
  }
}
EOF
            
            echo "âœ… Consumption summary created: $consumption_summary"
            echo "ðŸ“‹ Summary content:"
            cat "$consumption_summary" | jq '.'
          else
            echo "âš ï¸  No results file found for detailed consumption"
          fi
          
          # Set outputs
          echo "consumed-action-id=$ACTION_ID" >> $GITHUB_OUTPUT
          echo "performance-metrics=$performance_data" >> $GITHUB_OUTPUT
          echo "correlation-verified=$correlation_verified" >> $GITHUB_OUTPUT

      - name: Process Business Logic
        run: |
          ACTION_ID="${{ steps.consume.outputs.consumed-action-id }}"
          PERFORMANCE="${{ steps.consume.outputs.performance-metrics }}"
          CORRELATION_OK="${{ steps.consume.outputs.correlation-verified }}"
          
          echo "ðŸ­ Processing business logic with consumed results..."
          
          # Example business logic based on results
          if [[ -f "/tmp/consumption-summary-$ACTION_ID.json" ]]; then
            
            # Make business decisions based on results
            if command -v jq >/dev/null; then
              ops_per_sec=$(jq -r '.performance_metrics.operations_per_second // 0' "/tmp/consumption-summary-$ACTION_ID.json")
              
              if (( $(echo "$ops_per_sec > 1000" | bc -l 2>/dev/null || echo 0) )); then
                echo "ðŸš€ High performance detected ($ops_per_sec ops/sec) - triggering optimization pipeline"
                # Could trigger another async job here
                # ./scripts/pubsub/publisher.sh "optimize-$ACTION_ID" "optimization-requested" '{"reason":"high_performance"}'
              elif (( $(echo "$ops_per_sec > 0 && $ops_per_sec < 100" | bc -l 2>/dev/null || echo 0) )); then
                echo "âš ï¸  Low performance detected ($ops_per_sec ops/sec) - triggering investigation"
                # Could trigger investigation workflow
                # ./scripts/pubsub/publisher.sh "investigate-$ACTION_ID" "investigation-requested" '{"reason":"low_performance"}'
              else
                echo "ðŸ“Š Normal performance detected ($ops_per_sec ops/sec)"
              fi
            fi
            
            # Correlation tracking verification
            if [[ "$CORRELATION_OK" == "true" ]]; then
              echo "âœ… End-to-end correlation verified - audit trail complete"
            else
              echo "âš ï¸  Correlation verification failed - investigate traceability"
            fi
            
            # Could integrate with external systems here:
            # - Update database with results
            # - Send notifications
            # - Trigger downstream processes
            # - Generate reports
            # - Update dashboards
            
            echo "ðŸ’¼ Business logic processing complete"
          fi

      - name: Generate Consumption Report
        run: |
          ACTION_ID="${{ steps.consume.outputs.consumed-action-id }}"
          CORRELATION_ID="${{ steps.context.outputs.correlation-id }}"
          JOB_STATUS="${{ steps.consume.outputs.job-status }}"
          PERFORMANCE="${{ steps.consume.outputs.performance-metrics }}"
          CORRELATION_OK="${{ steps.consume.outputs.correlation-verified }}"
          TRIGGER_TYPE="${{ steps.context.outputs.trigger-type }}"
          
          cat >> $GITHUB_STEP_SUMMARY << EOF
          # ðŸ½ï¸ Async Results Consumption Report
          
          ## ðŸ“Š Consumption Overview
          
          | Attribute | Value |
          |-----------|-------|
          | **Consumed Action ID** | \`$ACTION_ID\` |
          | **Consumer Action ID** | \`${{ env.CONSUMER_ACTION_ID }}\` |
          | **Correlation ID** | \`${CORRELATION_ID:-'N/A'}\` |
          | **Trigger Type** | \`$TRIGGER_TYPE\` |
          | **Job Status** | \`$JOB_STATUS\` |
          | **Performance** | \`${PERFORMANCE:-'N/A'}\` ops/sec |
          | **Correlation Verified** | \`$CORRELATION_OK\` |
          | **Consumed At** | \`$(date -Iseconds)\` |
          
          ## ðŸ”„ State Feedback Loop Demonstrated
          
          ### âœ… Producer â†’ Consumer Flow
          1. ðŸš€ **Producer Workflow**: Published job and exited (non-blocking)
          2. âš¡ **Background Processing**: Async job executed independently
          3. ðŸ‘ï¸  **Completion Monitor**: Detected completion and triggered callback
          4. ðŸ”” **GitHub Callback**: repository_dispatch â†’ Consumer workflow triggered
          5. ðŸ½ï¸  **Consumer Workflow**: Retrieved results and processed business logic
          
          ### ðŸ“Š What Was Consumed
          $([[ "$JOB_STATUS" != "not-found" ]] && echo "- âœ… **Indexed Outputs**: Retrieved from async datastore" || echo "- âš ï¸  **Indexed Outputs**: Not found")
          $([[ "$CORRELATION_OK" == "true" ]] && echo "- âœ… **Correlation Tracking**: End-to-end traceability verified" || echo "- âŒ **Correlation Tracking**: Verification failed")  
          $([[ -n "$PERFORMANCE" && "$PERFORMANCE" != "N/A" ]] && echo "- âœ… **Performance Metrics**: $PERFORMANCE operations per second" || echo "- âš ï¸  **Performance Metrics**: Not available")
          - âœ… **Business Logic**: Processed based on results
          
          ## ðŸ” Manual Query Commands
          
          You can also query results manually:
          
          \`\`\`bash
          # Get current status
          ./scripts/pubsub/output-query-api.sh get-status "$ACTION_ID" math
          
          # Get processing logs  
          ./scripts/pubsub/output-query-api.sh get-logs "$ACTION_ID" math 50
          
          # Search for correlation ID
          ./scripts/pubsub/output-query-api.sh search "$ACTION_ID" math "$CORRELATION_ID"
          
          # View consumption summary
          cat /tmp/consumption-summary-$ACTION_ID.json | jq '.'
          \`\`\`
          
          ## ðŸŽ¯ Challenge Solved: Async State Feedback to GitHub âœ…
          
          This demonstrates the complete **async state feedback loop**:
          - âš¡ **Non-blocking**: Producer workflow finished in seconds
          - ðŸ”„ **Independent Processing**: Business logic ran asynchronously  
          - ðŸ”” **Automatic Callback**: GitHub was notified when complete
          - ðŸ½ï¸  **Result Consumption**: Consumer workflow processed final results
          - ðŸ’¼ **Business Integration**: Results used for downstream decisions
          
          **The async pub/sub pipeline with state feedback is fully operational! ðŸŽ‰**
          EOF
          
          echo "ðŸŽ‰ Consumption report generated successfully!"

  # ================================
  # ARCHIVE CONSUMED RESULTS (Optional)
  # ================================
  archive-results:
    needs: consume-async-results
    runs-on: self-hosted
    if: always()
    steps:
      - name: Archive Processing Results
        run: |
          ACTION_ID="${{ needs.consume-async-results.outputs.consumed-action-id }}"
          
          echo "ðŸ“¦ Archiving consumed results for: $ACTION_ID"
          
          # Create archive directory
          archive_dir="/tmp/archived-results/$(date +%Y-%m-%d)"
          mkdir -p "$archive_dir"
          
          # Archive files
          for file in "/tmp/math-results-$ACTION_ID.json" "/tmp/consumption-summary-$ACTION_ID.json" "/tmp/consumer-logs-$ACTION_ID.txt"; do
            if [[ -f "$file" ]]; then
              cp "$file" "$archive_dir/"
              echo "ðŸ“„ Archived: $(basename "$file")"
            fi
          done
          
          # Create archive manifest
          cat > "$archive_dir/manifest-$ACTION_ID.json" << EOF
{
  "action_id": "$ACTION_ID",
  "archived_at": "$(date -Iseconds)",
  "consumer_run_id": "${{ github.run_id }}",
  "repository": "${{ github.repository }}",
  "files_archived": [
    $(find "$archive_dir" -name "*$ACTION_ID*" -printf '"%f",' | sed 's/,$//')
  ]
}
EOF
          
          echo "âœ… Results archived to: $archive_dir"
          echo "ðŸ“‹ Archive manifest:"
          cat "$archive_dir/manifest-$ACTION_ID.json" | jq '.'